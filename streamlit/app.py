# –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫—É streamlit
import streamlit as st           # version 1.16.0

# –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±—â–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
import os
import numpy as np               # version 1.24.3
import pandas as pd              # version 1.5.3
import pysrt                     # version 1.1.2
import spacy                     # version 3.3.1
import en_core_web_sm            # version 3.3.0
import re
import chardet                   # version 5.1.0
from joblib import load          # version 1.1.1

# –ø—É—Ç—å –∑–∞–≥—Ä—É–∂–∞–µ–º–æ–π –º–æ–¥–µ–ª–∏
MODEL_NAME = '../models/model_bayesNB.joblib'

# –ø—É—Ç—å –∑–∞–≥—Ä—É–∂–∞–µ–º–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è oxford
OXFORD_NAME = '../oxford/classic_oxford.joblib'

# –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
PATHNAME = os.path.dirname(__file__)

# –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
model = load(os.path.join(PATHNAME, MODEL_NAME))

# –∑–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è oxford
oxford_words = load(os.path.join(PATHNAME, OXFORD_NAME))

# —Å–ª–æ–≤–∞—Ä—å —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π —É—Ä–æ–≤–Ω—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
LEVEL = {1: 'A2',
         2: 'B1',
         3: 'B2',
         4: 'C1'}

# Header —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title='–£—Ä–æ–≤–µ–Ω—å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –≤ —Å—É–±—Ç–∏—Ç—Ä–∞—Ö',
                   page_icon='üéû',
                   layout="centered",
                   initial_sidebar_state="auto",
                   menu_items=None)

with st.container():
    st.header('–£–∑–Ω–∞–π—Ç–µ —É—Ä–æ–≤–µ–Ω—å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –ø–æ —Å—É–±—Ç–∏—Ç—Ä–∞–º —Ñ–∏–ª—å–º–æ–≤ üéû!')

sub_file = st.file_uploader('–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ .srt', type='.srt', key=None)
st.markdown('–°–∫–∞—á–∞—Ç—å —Å—É–±—Ç–∏—Ç—Ä—ã –¥–ª—è —Ñ–∏–ª—å–º–∞ –≤—ã –º–æ–∂–µ—Ç–µ –Ω–∞ —Å–∞–π—Ç–µ: https://www.opensubtitles.org/ru/search/sublanguageid-eng')

# –∑–∞–¥–∞–¥–∏–º —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
HTML = r'<.*?>'  # html —Ç—ç–≥–∏ –º–µ–Ω—è–µ–º –Ω–∞ –ø—Ä–æ–±–µ–ª
TAG = r'{.*?}'  # —Ç—ç–≥–∏ –º–µ–Ω—è–µ–º –Ω–∞ –ø—Ä–æ–±–µ–ª
COMMENTS = r'[\(\[][A-Za-z ]+[\)\]]'  # –∫–æ–º–º–µ–Ω—Ç—ã –≤ —Å–∫–æ–±–∫–∞—Ö –º–µ–Ω—è–µ–º –Ω–∞ –ø—Ä–æ–±–µ–ª
LETTERS = r'[^a-zA-Z\.,!? ]'  # –≤—Å–µ —á—Ç–æ –Ω–µ –±—É–∫–≤—ã –º–µ–Ω—è–µ–º –Ω–∞ –ø—Ä–æ–±–µ–ª
SPACES = r'([ ])\1+'  # –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø—Ä–æ–±–µ–ª—ã –º–µ–Ω—è–µ–º –Ω–∞ –æ–¥–∏–Ω –ø—Ä–æ–±–µ–ª
DOTS = r'[\.]+'  # –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ –º–µ–Ω—è–µ–º –Ω–∞ —Ç–æ—á–∫—É


# —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤
def clean_subs(subs):
    subs = subs[1:]  # —É–¥–∞–ª—è–µ–º –ø–µ—Ä–≤—ã–π —Ä–µ–∫–ª–∞–º–Ω—ã–π —Å—É–±—Ç–∏—Ç—Ä
    txt = re.sub(HTML, ' ', subs.text)  # html —Ç—ç–≥–∏ –º–µ–Ω—è–µ–º –Ω–∞ –ø—Ä–æ–±–µ–ª
    txt = re.sub(COMMENTS, ' ', txt)  # –∫–æ–º–º–µ–Ω—Ç—ã –≤ —Å–∫–æ–±–∫–∞—Ö –º–µ–Ω—è–µ–º –Ω–∞ –ø—Ä–æ–±–µ–ª
    txt = re.sub(LETTERS, ' ', txt)  # –≤—Å–µ —á—Ç–æ –Ω–µ –±—É–∫–≤—ã –º–µ–Ω—è–µ–º –Ω–∞ –ø—Ä–æ–±–µ–ª
    txt = re.sub(DOTS, r'.', txt)  # –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ –º–µ–Ω—è–µ–º –Ω–∞ —Ç–æ—á–∫—É
    txt = re.sub(SPACES, r'\1', txt)  # –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø—Ä–æ–±–µ–ª—ã –º–µ–Ω—è–µ–º –Ω–∞ –æ–¥–∏–Ω –ø—Ä–æ–±–µ–ª
    txt = re.sub('www', '', txt)  # –∫–æ–µ-–≥–¥–µ –æ—Å—Ç–∞—ë—Ç—Å—è www, —Ç–æ –∂–µ –º–µ–Ω—è–µ–º –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
    txt = txt.lstrip()  # –æ–±—Ä–µ–∑–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤ —Å–ª–µ–≤–∞
    txt = txt.encode('ascii', 'ignore').decode()  # —É–¥–∞–ª—è–µ–º –≤—Å–µ —á—Ç–æ –Ω–µ ascii —Å–∏–º–≤–æ–ª—ã
    txt = txt.lower()  # —Ç–µ–∫—Å—Ç –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä
    return txt


# —Ñ—É–Ω–∫—Ü–∏—è –≤–æ–∑–≤—Ä–∞—â–∞—é—â–∞—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–µ–º–º
# –≤ —Ç–µ–∫—Å—Ç–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –ø–æ –∫–∞–∂–¥–æ–º—É —É—Ä–æ–≤–Ω—é
def lemma_count(lemmas, oxf, cat):
    func_dict = {'A1': 0,
                 'A2': 1,
                 'B1': 2,
                 'B2': 3,
                 'C1': 4}
    level = func_dict[cat]
    oxf_word_list = oxf[level].split()
    words = [lemma for lemma in lemmas if lemma in oxf_word_list]

    return len(set(words))


# –∑–∞–≥—Ä—É–∑–∏–º –¥–ª—è —Ñ–∏–ª—å–º–∞ —Å—É–±—Ç–∏—Ç—Ä—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ pysrt
def sub_process(subs):
    # –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫–∏–∏ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
    cln_subs = clean_subs(subs)
    df = pd.DataFrame({'subs': cln_subs}, index=[0])
    # –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫—É spacy –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏
    nlp = spacy.load("en_core_web_sm")
    doc = nlp(cln_subs)
    lemma_list = [token.lemma_ for token in doc]
    # –≤ —Ü–∏–∫–ª–µ –ø–æ –∫–∞–∂–¥–æ–π –º–µ—Ç–∫–µ –∑–∞–ø–∏—à–µ–º –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –∫–æ–ª-–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–µ–º–º
    for lvl in ['A1', 'A2', 'B1', 'B2', 'C1']:
        df.loc[0, lvl + '_lemma_cnt'] = lemma_count(lemma_list, oxford_words, lvl)
    return df


# –≤ —Å–ª—É—á–∞–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –∏ –æ—Ç–∫—Ä—ã–≤–∞–µ–º —Å –ø–æ–º–æ—â—å—é pysrt
if sub_file:
    with st.spinner('–æ–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏...'):
        try:
            encode = chardet.detect(sub_file.getvalue())['encoding']
            subtitles = pysrt.from_string(sub_file.getvalue().decode(encode))
            df = sub_process(subtitles)
            predictions = model.predict(df)
            st.subheader(f'–£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ñ–∏–ª—å–º–∞: {LEVEL[predictions[0]]}')
            # –ø–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ Oxford –≤ —Ç–µ–∫—Å—Ç–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤
            with st.container():
                a1 = df['A1_lemma_cnt'].values[0]
                a2 = df['A2_lemma_cnt'].values[0]
                b1 = df['B1_lemma_cnt'].values[0]
                b2 = df['B2_lemma_cnt'].values[0]
                c1 = df['C1_lemma_cnt'].values[0]
                word_all = a1 + a2 + b1 + b2 + c1
                a1_ratio = a1 / word_all
                a2_ratio = a2 / word_all
                b1_ratio = b1 / word_all
                b2_ratio = b2 / word_all
                c1_ratio = c1 / word_all
                st.write('–£–∑–Ω–∞–π—Ç–µ, —Å–∫–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ —Ñ–∏–ª—å–º–µ —Å–æ–≥–ª–∞—Å–Ω–æ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–≥–æ Oxford —Å–ª–æ–≤–∞—Ä—è:')
                st.progress(a1_ratio, text=f"—Å–ª–æ–≤ —É—Ä–æ–≤–Ω—è A1: {round(a1)}")
                st.progress(a2_ratio, text=f"—Å–ª–æ–≤ —É—Ä–æ–≤–Ω—è A2: {round(a2)}")
                st.progress(b1_ratio, text=f"—Å–ª–æ–≤ —É—Ä–æ–≤–Ω—è B1: {round(b1)}")
                st.progress(b2_ratio, text=f"—Å–ª–æ–≤ —É—Ä–æ–≤–Ω—è B2: {round(b2)}")
                st.progress(c1_ratio, text=f"—Å–ª–æ–≤ —É—Ä–æ–≤–Ω—è C1: {round(c1)}")

        except Exception as e:
            st.error(f'–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –µ—â–µ —Ä–∞–∑!')
            print(e)